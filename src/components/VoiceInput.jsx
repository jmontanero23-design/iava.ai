/**
 * VoiceInput - Elite Voice Command Component
 *
 * PhD++ Quality Web Speech API integration for hands-free trading:
 * - Real-time speech-to-text
 * - Voice command processing
 * - Visual feedback (waveform, state indicators)
 * - Command suggestions
 * - Multi-language support
 *
 * Commands supported:
 * - "Load [symbol]" - Load a symbol on chart
 * - "Buy [amount] [symbol]" - Create buy order
 * - "Sell [amount] [symbol]" - Create sell order
 * - "Show forecast" - Open Chronos forecast
 * - "Set alert at [price]" - Create price alert
 * - "What's [symbol] price" - Get current price
 */

import React, { useState, useEffect, useRef, useCallback } from 'react'

// Check browser support
const SpeechRecognition = typeof window !== 'undefined' && (
  window.SpeechRecognition || window.webkitSpeechRecognition
)
const hasSpeechSupport = !!SpeechRecognition

// Voice command patterns
const COMMAND_PATTERNS = [
  {
    pattern: /^(load|show|open|chart)\s+(\w+)$/i,
    action: 'LOAD_SYMBOL',
    extract: (match) => ({ symbol: match[2].toUpperCase() })
  },
  {
    pattern: /^buy\s+(\d+)?\s*(?:shares?\s+(?:of\s+)?)?(\w+)$/i,
    action: 'BUY',
    extract: (match) => ({ quantity: parseInt(match[1]) || 1, symbol: match[2].toUpperCase() })
  },
  {
    pattern: /^sell\s+(\d+)?\s*(?:shares?\s+(?:of\s+)?)?(\w+)$/i,
    action: 'SELL',
    extract: (match) => ({ quantity: parseInt(match[1]) || 1, symbol: match[2].toUpperCase() })
  },
  {
    pattern: /^(show|open)?\s*(forecast|prediction|chronos)$/i,
    action: 'SHOW_FORECAST',
    extract: () => ({})
  },
  {
    pattern: /^set\s+alert\s+(?:at\s+)?(\$?[\d.]+)$/i,
    action: 'SET_ALERT',
    extract: (match) => ({ price: parseFloat(match[1].replace('$', '')) })
  },
  {
    pattern: /^(?:what'?s?|get)\s+(\w+)\s+price$/i,
    action: 'GET_PRICE',
    extract: (match) => ({ symbol: match[1].toUpperCase() })
  },
  {
    pattern: /^stop\s+(?:all\s+)?trading$/i,
    action: 'EMERGENCY_STOP',
    extract: () => ({})
  },
  {
    pattern: /^pause\s+(?:trading)?$/i,
    action: 'PAUSE_TRADING',
    extract: () => ({})
  },
  {
    pattern: /^(?:show|open)\s+(portfolio|positions)$/i,
    action: 'SHOW_PORTFOLIO',
    extract: () => ({})
  },
  {
    pattern: /^(?:show|open)\s+(ai\s+hub|chat|copilot)$/i,
    action: 'SHOW_AI',
    extract: () => ({})
  }
]

// Suggested commands for help
const SUGGESTED_COMMANDS = [
  { text: 'Load AAPL', description: 'Show Apple on chart' },
  { text: 'Buy 10 SPY', description: 'Buy 10 shares of SPY' },
  { text: 'Show forecast', description: 'Open AVA forecast' },
  { text: 'Set alert at 150', description: 'Alert when price hits $150' },
  { text: "What's NVDA price", description: 'Get NVIDIA price' },
  { text: 'Show portfolio', description: 'View your positions' }
]

export default function VoiceInput({
  onCommand,
  onTranscript,
  onClose,
  showSuggestions = true,
  autoStart = false,
  className = ''
}) {
  const [isListening, setIsListening] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [interimTranscript, setInterimTranscript] = useState('')
  const [error, setError] = useState(null)
  const [volume, setVolume] = useState(0)
  const [parsedCommand, setParsedCommand] = useState(null)

  const recognitionRef = useRef(null)
  const audioContextRef = useRef(null)
  const analyserRef = useRef(null)
  const animationRef = useRef(null)

  // Parse transcript into command
  const parseCommand = useCallback((text) => {
    const cleaned = text.trim().toLowerCase()

    for (const cmd of COMMAND_PATTERNS) {
      const match = cleaned.match(cmd.pattern)
      if (match) {
        return {
          action: cmd.action,
          params: cmd.extract(match),
          raw: text
        }
      }
    }

    return null
  }, [])

  // Execute command
  const executeCommand = useCallback((command) => {
    switch (command.action) {
      case 'LOAD_SYMBOL':
        window.dispatchEvent(new CustomEvent('iava.loadSymbol', {
          detail: { symbol: command.params.symbol }
        }))
        window.dispatchEvent(new CustomEvent('iava.toast', {
          detail: { text: `Loading ${command.params.symbol}...`, type: 'info' }
        }))
        break

      case 'BUY':
      case 'SELL':
        window.dispatchEvent(new CustomEvent('ai-trade-setup', {
          detail: {
            symbol: command.params.symbol,
            side: command.action.toLowerCase(),
            quantity: command.params.quantity,
            source: 'voice'
          }
        }))
        window.dispatchEvent(new CustomEvent('iava.toast', {
          detail: {
            text: `${command.action} ${command.params.quantity} ${command.params.symbol} - Review order`,
            type: command.action === 'BUY' ? 'success' : 'warning'
          }
        }))
        break

      case 'SHOW_FORECAST':
        window.dispatchEvent(new CustomEvent('iava.setActiveTab', { detail: { tab: 'forecast' } }))
        break

      case 'SET_ALERT':
        window.dispatchEvent(new CustomEvent('ava.createPriceAlert', {
          detail: { targetPrice: command.params.price }
        }))
        window.dispatchEvent(new CustomEvent('iava.toast', {
          detail: { text: `Alert set at $${command.params.price}`, type: 'success' }
        }))
        break

      case 'GET_PRICE':
        window.dispatchEvent(new CustomEvent('iava.loadSymbol', {
          detail: { symbol: command.params.symbol }
        }))
        break

      case 'EMERGENCY_STOP':
        window.dispatchEvent(new CustomEvent('ava.emergencyStop', { detail: { active: true } }))
        break

      case 'PAUSE_TRADING':
        window.dispatchEvent(new CustomEvent('ava.pauseTrading'))
        break

      case 'SHOW_PORTFOLIO':
        window.dispatchEvent(new CustomEvent('iava.setActiveTab', { detail: { tab: 'portfolio' } }))
        break

      case 'SHOW_AI':
        window.dispatchEvent(new CustomEvent('iava.setActiveTab', { detail: { tab: 'ai-hub' } }))
        break

      default:
        break
    }

    onCommand?.(command)
  }, [onCommand])

  // Initialize speech recognition
  useEffect(() => {
    if (!hasSpeechSupport) {
      setError('Speech recognition not supported in this browser')
      return
    }

    const recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = 'en-US'

    recognition.onstart = () => {
      setIsListening(true)
      setError(null)
    }

    recognition.onend = () => {
      setIsListening(false)
    }

    recognition.onerror = (event) => {
      setIsListening(false)
      if (event.error === 'not-allowed') {
        setError('Microphone access denied. Please enable microphone permissions.')
      } else if (event.error !== 'aborted') {
        setError(`Speech recognition error: ${event.error}`)
      }
    }

    recognition.onresult = (event) => {
      let interim = ''
      let final = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript
        if (event.results[i].isFinal) {
          final += transcript
        } else {
          interim += transcript
        }
      }

      setInterimTranscript(interim)

      if (final) {
        setTranscript(final)
        onTranscript?.(final)

        // Parse and potentially execute command
        const command = parseCommand(final)
        if (command) {
          setParsedCommand(command)
          executeCommand(command)
        }
      }
    }

    recognitionRef.current = recognition

    if (autoStart) {
      startListening()
    }

    return () => {
      recognition.abort()
    }
  }, [autoStart, parseCommand, executeCommand, onTranscript])

  // Audio visualization
  useEffect(() => {
    if (!isListening) {
      setVolume(0)
      return
    }

    let mounted = true

    const setupAudio = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        audioContextRef.current = new AudioContext()
        analyserRef.current = audioContextRef.current.createAnalyser()
        const source = audioContextRef.current.createMediaStreamSource(stream)
        source.connect(analyserRef.current)
        analyserRef.current.fftSize = 256

        const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)

        const updateVolume = () => {
          if (!mounted || !isListening) return

          analyserRef.current.getByteFrequencyData(dataArray)
          const average = dataArray.reduce((a, b) => a + b) / dataArray.length
          setVolume(average / 255)

          animationRef.current = requestAnimationFrame(updateVolume)
        }

        updateVolume()
      } catch (err) {
        console.error('Audio setup error:', err)
      }
    }

    setupAudio()

    return () => {
      mounted = false
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current)
      }
      if (audioContextRef.current) {
        audioContextRef.current.close()
      }
    }
  }, [isListening])

  // Start listening
  const startListening = useCallback(() => {
    if (recognitionRef.current && !isListening) {
      setTranscript('')
      setInterimTranscript('')
      setParsedCommand(null)
      try {
        recognitionRef.current.start()
      } catch (err) {
        console.error('Start error:', err)
      }
    }
  }, [isListening])

  // Stop listening
  const stopListening = useCallback(() => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop()
    }
  }, [isListening])

  // Toggle listening
  const toggleListening = useCallback(() => {
    if (isListening) {
      stopListening()
    } else {
      startListening()
    }
  }, [isListening, startListening, stopListening])

  if (!hasSpeechSupport) {
    return (
      <div className={`p-4 bg-red-900/20 border border-red-500/30 rounded-xl ${className}`}>
        <p className="text-red-400 text-sm">
          Voice input is not supported in this browser. Please use Chrome, Edge, or Safari.
        </p>
      </div>
    )
  }

  return (
    <div className={`bg-slate-900/95 backdrop-blur-xl rounded-2xl border border-slate-800/50 overflow-hidden ${className}`}>
      {/* Header */}
      <div className="p-4 border-b border-slate-800/50">
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-3">
            <div className={`
              w-10 h-10 rounded-full flex items-center justify-center text-xl
              ${isListening
                ? 'bg-gradient-to-r from-cyan-500/30 to-blue-500/30 animate-pulse'
                : 'bg-slate-800'
              }
            `}>
              ğŸ¤
            </div>
            <div>
              <h3 className="text-white font-semibold">Voice Command</h3>
              <p className="text-xs text-slate-400">
                {isListening ? 'Listening...' : 'Tap mic to start'}
              </p>
            </div>
          </div>
          {onClose && (
            <button
              onClick={onClose}
              className="p-2 text-slate-400 hover:text-white rounded-lg hover:bg-slate-800/50 transition-colors"
            >
              <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
              </svg>
            </button>
          )}
        </div>
      </div>

      {/* Mic button and visualization */}
      <div className="p-6 flex flex-col items-center">
        {/* Waveform visualization */}
        <div className="relative mb-6">
          {/* Pulse rings */}
          {isListening && (
            <>
              <div
                className="absolute inset-0 rounded-full bg-cyan-500/20 animate-ping"
                style={{ animationDuration: '1.5s', transform: `scale(${1 + volume * 0.5})` }}
              />
              <div
                className="absolute inset-0 rounded-full bg-cyan-500/10"
                style={{ transform: `scale(${1.3 + volume * 0.3})` }}
              />
            </>
          )}

          {/* Mic button */}
          <button
            onClick={toggleListening}
            className={`
              relative w-20 h-20 rounded-full flex items-center justify-center
              transition-all duration-200 transform active:scale-95
              ${isListening
                ? 'bg-gradient-to-r from-cyan-500 to-blue-500 shadow-lg shadow-cyan-500/40'
                : 'bg-slate-800 hover:bg-slate-700'
              }
            `}
          >
            <span className="text-3xl">{isListening ? 'ğŸ™ï¸' : 'ğŸ¤'}</span>

            {/* Volume indicator */}
            {isListening && (
              <div
                className="absolute inset-0 rounded-full border-4 border-cyan-400"
                style={{
                  opacity: 0.3 + volume * 0.7,
                  transform: `scale(${1 + volume * 0.15})`
                }}
              />
            )}
          </button>
        </div>

        {/* Transcript display */}
        <div className="w-full min-h-[60px] p-4 bg-slate-800/30 rounded-xl text-center">
          {error ? (
            <p className="text-red-400 text-sm">{error}</p>
          ) : transcript || interimTranscript ? (
            <div>
              <p className="text-white">
                {transcript}
                <span className="text-slate-500">{interimTranscript}</span>
              </p>
              {parsedCommand && (
                <div className="mt-2 inline-flex items-center gap-2 px-3 py-1 bg-cyan-500/20 text-cyan-400 rounded-full text-sm">
                  <span>âœ“</span>
                  <span>{parsedCommand.action.replace('_', ' ')}</span>
                </div>
              )}
            </div>
          ) : (
            <p className="text-slate-500 text-sm">
              {isListening ? 'Say a command...' : 'Tap the mic and speak'}
            </p>
          )}
        </div>
      </div>

      {/* Suggested commands */}
      {showSuggestions && !isListening && (
        <div className="px-4 pb-4">
          <p className="text-xs text-slate-500 mb-2">Try saying:</p>
          <div className="flex flex-wrap gap-2">
            {SUGGESTED_COMMANDS.slice(0, 4).map((cmd, i) => (
              <button
                key={i}
                onClick={() => {
                  setTranscript(cmd.text)
                  const command = parseCommand(cmd.text)
                  if (command) {
                    setParsedCommand(command)
                    executeCommand(command)
                  }
                }}
                className="px-3 py-1.5 bg-slate-800/50 hover:bg-slate-700/50 rounded-lg text-sm text-slate-300 transition-colors"
                title={cmd.description}
              >
                "{cmd.text}"
              </button>
            ))}
          </div>
        </div>
      )}
    </div>
  )
}

// Floating Voice Button
export function VoiceButton({
  onClick,
  isListening = false,
  className = ''
}) {
  return (
    <button
      onClick={onClick}
      className={`
        relative w-14 h-14 rounded-full flex items-center justify-center
        transition-all duration-200 shadow-lg
        ${isListening
          ? 'bg-gradient-to-r from-cyan-500 to-blue-500 shadow-cyan-500/40 animate-pulse'
          : 'bg-slate-800 hover:bg-slate-700 shadow-black/30'
        }
        ${className}
      `}
      title="Voice command"
    >
      <span className="text-2xl">{isListening ? 'ğŸ™ï¸' : 'ğŸ¤'}</span>

      {isListening && (
        <div className="absolute inset-0 rounded-full border-2 border-cyan-400/50 animate-ping" />
      )}
    </button>
  )
}

// Compact inline voice input
export function InlineVoiceInput({
  onTranscript,
  placeholder = 'Speak or type...',
  className = ''
}) {
  const [isListening, setIsListening] = useState(false)
  const [text, setText] = useState('')

  return (
    <div className={`relative flex items-center ${className}`}>
      <input
        type="text"
        value={text}
        onChange={(e) => setText(e.target.value)}
        placeholder={placeholder}
        className="w-full pl-4 pr-12 py-3 bg-slate-800/50 border border-slate-700/50 rounded-xl text-white placeholder-slate-500 focus:outline-none focus:ring-2 focus:ring-cyan-500/30"
      />
      <button
        onClick={() => setIsListening(!isListening)}
        className={`
          absolute right-2 w-8 h-8 rounded-lg flex items-center justify-center
          transition-colors
          ${isListening
            ? 'bg-cyan-500/30 text-cyan-400'
            : 'text-slate-400 hover:text-white hover:bg-slate-700/50'
          }
        `}
      >
        <span className="text-lg">{isListening ? 'ğŸ™ï¸' : 'ğŸ¤'}</span>
      </button>
    </div>
  )
}
